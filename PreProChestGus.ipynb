{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "import cvxEDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_dict = {'ACC': 700, 'ECG': 700, 'EMG': 700, 'EDA': 700, 'Temp': 700, 'Resp': 700, 'label': 700}\n",
    "WINDOW_IN_SECONDS = 30\n",
    "STRIDE_IN_SECONDS = 0.5\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 3}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 3: 'amusement'}\n",
    "feat_names = None\n",
    "DATA_PATH = r'C:\\Users\\IALAB\\Downloads\\WESAD-master\\data\\WESAD/'\n",
    "SAVE_PATH = r'C:\\Users\\IALAB\\Downloads\\WESAD-master\\data_sync_30_05/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def eda_stats(y):\n",
    "#    Fs = fs_dict['EDA']\n",
    "#    yn = (y - y.mean()) / y.std()\n",
    "#    print(yn)\n",
    "#    print(\"calculating eda stats\")\n",
    "#    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1. / Fs)\n",
    "#    return [r, p, t, l, d, e, obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_stats(y, ventana_segundos):\n",
    "    Fs = fs_dict['EDA']  # Frecuencia de muestreo (700 Hz)\n",
    "    ventana_muestras = ventana_segundos * Fs  # Convertir segundos a muestras\n",
    "\n",
    "    # Inicializar listas vacías para almacenar los resultados completos\n",
    "    eda_phasic = []\n",
    "    eda_smna = []\n",
    "    eda_tonic = []\n",
    "    scr_counts = []  # Para contar los SCR (respuestas de la piel)\n",
    "\n",
    "    print(\"Procesando EDA en segmentos...\")\n",
    "\n",
    "    for inicio in range(0, len(y), ventana_muestras):  \n",
    "        fin = min(inicio + ventana_muestras, len(y))\n",
    "        y_segmento = y[inicio:fin]\n",
    "\n",
    "        # Normalizar el segmento\n",
    "        yn = (y_segmento - y_segmento.mean()) / y_segmento.std()\n",
    "\n",
    "        if len(yn) < 2:  # Evitar procesar segmentos vacíos\n",
    "            continue  \n",
    "\n",
    "        # Aplicar cvxEDA\n",
    "        r, p, t, _, _, _, _ = cvxEDA.cvxEDA(yn, 1. / Fs)\n",
    "\n",
    "        # Concatenar los resultados en las listas\n",
    "        eda_phasic.extend(r)\n",
    "        eda_smna.extend(p)\n",
    "        eda_tonic.extend(t)\n",
    "        \n",
    "        # Contar SCR como cambios positivos en la señal fásica\n",
    "        scr_counts.append(np.sum(np.diff(p) > 0.01))  \n",
    "\n",
    "    print(\"✅ Procesamiento de EDA completado\")\n",
    "    \n",
    "    # Convertir a arrays de numpy antes de retornar\n",
    "    return np.array(eda_phasic), np.array(eda_smna), np.array(eda_tonic), np.array(scr_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        self.subject_keys = ['signal', 'label', 'subject']\n",
    "        self.signal_keys = ['chest', 'wrist']\n",
    "        self.chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "        self.wrist_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        with open(os.path.join(main_path, self.name) + '/' + self.name + '.pkl', 'rb') as file:\n",
    "            self.data = pickle.load(file, encoding='latin1')\n",
    "        self.labels = self.data['label']\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        data = self.data['signal']['wrist']\n",
    "        data.update({'Resp': self.data['signal']['chest']['Resp']})\n",
    "        return data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        return self.data['signal']['chest']\n",
    "\n",
    "    def extract_features(self):  # only wrist\n",
    "        results = \\\n",
    "            {\n",
    "                key: get_statistics(self.get_chest_data()[key].flatten(), self.labels, key)\n",
    "                for key in self.chest_keys\n",
    "            }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass(cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    # Filtering Helper functions\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = scisig.lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def get_slope(series):\n",
    "    linreg = scipy.stats.linregress(np.arange(len(series)), series )\n",
    "    slope = linreg[0]\n",
    "    return slope\n",
    "\n",
    "def get_peak_freq(x, fs):\n",
    "    f, Pxx = scisig.periodogram(x, fs=fs)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    return psd_dict[max(psd_dict.keys())]\n",
    "\n",
    "def get_window_stats(data, label=-1):\n",
    "    mean_features = np.mean(data)\n",
    "    std_features = np.std(data)\n",
    "    min_features = np.amin(data)\n",
    "    max_features = np.amax(data)\n",
    "\n",
    "    features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                'label': label}\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_net_accel(data):\n",
    "    return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "\n",
    "def get_peak_freq(x):\n",
    "    f, Pxx = scisig.periodogram(x, fs=8)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    return peak_freq\n",
    "\n",
    "\n",
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "def filterSignalFIR(eda, cutoff=0.4, numtaps=64):\n",
    "    f = cutoff / (fs_dict['ACC'] / 2.0)\n",
    "    FIR_coeff = scisig.firwin(numtaps, f)\n",
    "\n",
    "    return scisig.lfilter(FIR_coeff, 1, eda.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data_dict, labels, fs_dict, norm_type=None):\n",
    "    ecg_df = pd.DataFrame(data_dict['ECG'], columns=['ECG'])\n",
    "    eda_df = pd.DataFrame(data_dict['EDA'], columns=['EDA'])\n",
    "    emg_df = pd.DataFrame(data_dict['EMG'], columns=['EMG'])\n",
    "    temp_df = pd.DataFrame(data_dict['Temp'], columns=['Temp'])\n",
    "    resp_df = pd.DataFrame(data_dict['Resp'], columns=['Resp'])\n",
    "    label_df = pd.DataFrame(labels, columns=['label'])\n",
    "    print(fs_dict.keys())\n",
    "    \n",
    "    eda_df['EDA'] = butter_lowpass_filter(eda_df['EDA'], 5.0, fs_dict['EDA'], 6)  # Filtro 5 Hz\n",
    "    resp_df['Resp'] = butter_lowpass_filter(resp_df['Resp'], 0.35, fs_dict['Resp'], 4)  # 0.1 - 0.35 Hz\n",
    "    \n",
    "    # Calcular estadísticas de EDA\n",
    "    r, p, t, num_scr = eda_stats(eda_df['EDA'].values.flatten(), WINDOW_IN_SECONDS)\n",
    "    eda_df['EDA_phasic'] = r\n",
    "    print(eda_df['EDA_phasic'].shape)\n",
    "    eda_df['EDA_smna'] = p\n",
    "    print(eda_df['EDA_smna'].shape)\n",
    "    eda_df['EDA_tonic'] = t\n",
    "    print(eda_df['EDA_tonic'].shape)\n",
    "    #eda_df['SCR_count'] = num_scr\n",
    "    \n",
    "    # Calcular frecuencia cardíaca\n",
    "    hr_values = 60 / np.diff(np.where(ecg_df['ECG'] > np.mean(ecg_df['ECG']))[0])\n",
    "\n",
    "    # Interpolar para que coincida con el tamaño de ecg_df\n",
    "    ecg_df['HR'] = np.interp(np.arange(len(ecg_df)), np.arange(len(hr_values)), hr_values)\n",
    "    print(ecg_df['HR'].shape)\n",
    "\n",
    "    # Aplicar el filtro después\n",
    "    ecg_df['HR'] = butter_lowpass_filter(ecg_df['HR'], 2.0, fs_dict['ECG'], 4)\n",
    "    \n",
    "    # Calcular pendiente de temperatura\n",
    "    temp_df['Temp_slope'] = get_slope(temp_df['Temp'])\n",
    "    print(temp_df['Temp_slope'].shape)\n",
    "    \n",
    "    # Calcular tasa de respiración\n",
    "    resp_rate = np.sum(np.diff(resp_df['Resp']) > 0) / (len(resp_df) / fs_dict['Resp'])\n",
    "    resp_df['Resp_rate'] = resp_rate\n",
    "    print(resp_df['Resp_rate'].shape)\n",
    "    \n",
    "    # Unir los DataFrames\n",
    "    df = eda_df.join(ecg_df, how='outer')\n",
    "    df = df.join(emg_df, how='outer')\n",
    "    df = df.join(temp_df, how='outer')\n",
    "    df = df.join(resp_df, how='outer')\n",
    "    df = df.join(label_df, how='outer')\n",
    "    df['label'] = df['label'].fillna(method='bfill')\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Normalización\n",
    "    if norm_type == 'std':\n",
    "        df = (df - df.mean()) / df.std()\n",
    "    elif norm_type == 'minmax':\n",
    "        df = (df - df.min()) / (df.max() - df.min())\n",
    "    \n",
    "    # Agrupar por etiqueta\n",
    "    grouped = df.groupby('label')\n",
    "    print(grouped)\n",
    "\n",
    "    baseline = grouped.get_group(1)\n",
    "    print(baseline)\n",
    "    stress = grouped.get_group(2)\n",
    "    print(stress)\n",
    "    amusement = grouped.get_group(3)\n",
    "    print(amusement)\n",
    "\n",
    "    return grouped, baseline, stress, amusement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(data, label, stride_seconds):\n",
    "    global feat_names\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    samples = []\n",
    "    \n",
    "    # Convertir tiempo a muestras\n",
    "    window_len = int(fs_dict['label'] * WINDOW_IN_SECONDS)  # Asegurar que sea entero\n",
    "    stride_len = int(fs_dict['label'] * stride_seconds)  # Convertir stride a entero\n",
    "\n",
    "    print(\"El numero de datos esperados es de: \" + str(((len(data) - window_len) / stride_len) + 1))\n",
    "\n",
    "    # Crear ventanas solapadas\n",
    "    for start in range(0, len(data) - window_len + 1, stride_len):\n",
    "\n",
    "        print(f\"Ventana desde {start} hasta {start + window_len} (Índice {start})..........................\")\n",
    "        # Extraer ventana\n",
    "        w = data[start:start + window_len]\n",
    "\n",
    "        # Calcular estadísticas\n",
    "        wstats = get_window_stats(w, label=label)\n",
    "\n",
    "        if not wstats:  # Si get_window_stats() no devuelve nada, continuar\n",
    "            print(f\"⚠️ Advertencia: Ventana vacía en índice {start}, saltando...\")\n",
    "            continue\n",
    "\n",
    "        # Formatear en DataFrame\n",
    "        x = pd.DataFrame(wstats).drop('label', axis=0)\n",
    "        y = label  \n",
    "        x.drop('label', axis=1, inplace=True)\n",
    "\n",
    "        if feat_names is None:\n",
    "            feat_names = ['{}_{}'.format(row, col) for row in x.index for col in x.columns]\n",
    "\n",
    "        # **Asegurar que 'wdf' existe antes de usarlo**\n",
    "        wdf = pd.DataFrame(x.values.flatten()).T\n",
    "        wdf.columns = feat_names\n",
    "\n",
    "        # Verificar si feat_names y wdf tienen la misma cantidad de columnas\n",
    "        if len(feat_names) != wdf.shape[1]:\n",
    "            print(f\"⚠️ Advertencia: Ajustando feat_names ({len(feat_names)}) a {wdf.shape[1]}\")\n",
    "            feat_names = feat_names[:wdf.shape[1]]  # Ajustamos para evitar error\n",
    "\n",
    "        wdf = pd.concat([wdf, pd.DataFrame({'label': y}, index=[0])], axis=1)\n",
    "\n",
    "        # Extraer más características SOLO si existen en la ventana\n",
    "        if 'TEMP' in w:\n",
    "            wdf['TEMP_slope'] = get_slope(w['TEMP'].dropna())\n",
    "\n",
    "        # Guardar ventana\n",
    "        samples.append(wdf)\n",
    "\n",
    "    if not samples:\n",
    "        print(\"⚠️ Advertencia: No se generaron muestras en get_samples(), devolviendo DataFrame vacío.\")\n",
    "        return pd.DataFrame()  # Retornar DataFrame vacío en caso de error\n",
    "\n",
    "    return pd.concat(samples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patient_data(subject_id):\n",
    "    global SAVE_PATH\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    # Make subject data object for Sx\n",
    "    subject = SubjectData(main_path=r'C:\\Users\\IALAB\\Downloads\\WESAD-master\\data\\WESAD', subject_number=subject_id)\n",
    "\n",
    "    # Empatica E4 data - now with resp\n",
    "    data_dict = subject.get_chest_data()\n",
    "\n",
    "    print(data_dict.keys())\n",
    "    print(subject.labels)\n",
    "\n",
    "    # norm type\n",
    "    norm_type = None\n",
    "\n",
    "    # The 3 classes we are classifying\n",
    "\n",
    "    grouped, baseline, stress, amusement = compute_features(data_dict, subject.labels, fs_dict=fs_dict , norm_type=norm_type)\n",
    "    print(\"features calculated\")\n",
    "    # print(f'Available windows for {subject.name}:')\n",
    "    samples_per_window = int(fs_dict['label'] * WINDOW_IN_SECONDS)\n",
    "    stride_per_window = int(fs_dict['label'] * STRIDE_IN_SECONDS)\n",
    "\n",
    "    n_baseline_wdws = (len(baseline) - samples_per_window) / stride_per_window + 1\n",
    "    n_stress_wdws = (len(stress) - samples_per_window) / stride_per_window + 1\n",
    "    n_amusement_wdws = (len(amusement) - samples_per_window) / stride_per_window + 1\n",
    "    # print(f'Baseline: {n_baseline_wdws}\\nStress: {n_stress_wdws}\\nAmusement: {n_amusement_wdws}\\n')\n",
    "    print(f\"Procesando S{subject_id}:\")\n",
    "    print(f\"  - Baseline windows: {n_baseline_wdws}\")\n",
    "    print(f\"  - Stress windows: {n_stress_wdws}\")\n",
    "    print(f\"  - Amusement windows: {n_amusement_wdws}\")\n",
    "    #\n",
    "    baseline_samples = get_samples(baseline, label=1, stride_seconds = STRIDE_IN_SECONDS)\n",
    "    # Downsampling\n",
    "    # baseline_samples = baseline_samples[::2]\n",
    "    stress_samples = get_samples(stress, label=2, stride_seconds = STRIDE_IN_SECONDS)\n",
    "    amusement_samples = get_samples(amusement, label=3, stride_seconds = STRIDE_IN_SECONDS)\n",
    "\n",
    "    all_samples = pd.concat([baseline_samples, stress_samples, amusement_samples])\n",
    "    all_samples['label'] = all_samples['label'].astype(int)\n",
    "    all_samples = pd.concat([all_samples.drop('label', axis=1), pd.get_dummies(all_samples['label'])], axis=1)\n",
    "    # Selected Features\n",
    "    # all_samples = all_samples[['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max',\n",
    "    #                          'BVP_mean', 'BVP_std', 'BVP_min', 'BVP_max',\n",
    "    #                        'TEMP_mean', 'TEMP_std', 'TEMP_min', 'TEMP_max',\n",
    "    #                        'net_acc_mean', 'net_acc_std', 'net_acc_min', 'net_acc_max',\n",
    "    #                        0, 1, 2]]\n",
    "    # Save file as csv (for now)\n",
    "    all_samples.to_csv(f'{SAVE_PATH}/S{subject_id}_feats_4.csv')\n",
    "\n",
    "    # Does this save any space?\n",
    "    subject = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(subjects):\n",
    "    df_list = []\n",
    "    for s in subjects:\n",
    "        df = pd.read_csv(f'{SAVE_PATH}/S{s}_feats_4.csv', index_col=0)\n",
    "        df['subject'] = s\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "\n",
    "    print(df.head(10))\n",
    "    print(df.columns)\n",
    "\n",
    "    df['label'] = df[['1', '2', '3']].idxmax(axis=1).astype(int)\n",
    "    df.drop(['1', '2', '3'], axis=1, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.to_csv(f'{SAVE_PATH}/may14_feats4.csv')\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "\n",
    "    print(\"Índices en counts:\", counts.index.tolist())\n",
    "    print(\"Claves en int_to_label:\", int_to_label.keys())\n",
    "\n",
    "    print('Number of samples per class:')\n",
    "    for label, number in zip(counts.index, counts.values):\n",
    "        print(f'{int_to_label[label]}: {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "for patient in subject_ids:\n",
    "    print(f'Processing data for S{patient}...')\n",
    "    make_patient_data(patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    EDA_mean   EDA_std   EDA_min     EDA_max  EDA_phasic_mean  EDA_phasic_std  \\\n",
      "0  37.554971  0.182977 -6.214904  489.071196        37.554971        0.436898   \n",
      "0  37.554011  0.173115 -6.214904  489.071196        37.554011        0.387536   \n",
      "0  37.547265  0.166094 -6.796271  489.071196        37.547265        0.350867   \n",
      "0  37.536517  0.161628 -6.839681  489.071196        37.536517        0.327099   \n",
      "0  37.531246  0.157913 -6.839681  489.071196        37.531246        0.308344   \n",
      "0  37.532148  0.154735 -6.839681  489.071196        37.532148        0.293787   \n",
      "0  37.532966  0.152905 -6.839681  489.071196        37.532966        0.284846   \n",
      "0  37.531443  0.152449 -6.839681  489.071196        37.531443        0.279007   \n",
      "0  37.529940  0.151842 -6.839681  489.071196        37.529940        0.275925   \n",
      "0  37.525450  0.150702 -6.839681  489.071196        37.525450        0.275287   \n",
      "\n",
      "   EDA_phasic_min  EDA_phasic_max  EDA_smna_mean  EDA_smna_std  ...  Resp_min  \\\n",
      "0       -6.214904      489.071196      37.554971      6.106203  ... -6.214904   \n",
      "0       -6.214904      489.071196      37.554011      6.103891  ... -6.214904   \n",
      "0       -6.796271      489.071196      37.547265      6.144448  ... -6.796271   \n",
      "0       -6.839681      489.071196      37.536517      6.385621  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.531246      6.443162  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.532148      6.455946  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.532966      6.455533  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.531443      6.598017  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.529940      7.306178  ... -6.839681   \n",
      "0       -6.839681      489.071196      37.525450      7.259946  ... -6.839681   \n",
      "\n",
      "     Resp_max  Resp_rate_mean  Resp_rate_std  Resp_rate_min  Resp_rate_max  \\\n",
      "0  489.071196       37.554971   1.543299e-10      -6.214904     489.071196   \n",
      "0  489.071196       37.554011   1.543299e-10      -6.214904     489.071196   \n",
      "0  489.071196       37.547265   1.543299e-10      -6.796271     489.071196   \n",
      "0  489.071196       37.536517   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.531246   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.532148   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.532966   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.531443   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.529940   1.543299e-10      -6.839681     489.071196   \n",
      "0  489.071196       37.525450   1.543299e-10      -6.839681     489.071196   \n",
      "\n",
      "      1      2      3  subject  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "0  True  False  False        2  \n",
      "\n",
      "[10 rows x 48 columns]\n",
      "Index(['EDA_mean', 'EDA_std', 'EDA_min', 'EDA_max', 'EDA_phasic_mean',\n",
      "       'EDA_phasic_std', 'EDA_phasic_min', 'EDA_phasic_max', 'EDA_smna_mean',\n",
      "       'EDA_smna_std', 'EDA_smna_min', 'EDA_smna_max', 'EDA_tonic_mean',\n",
      "       'EDA_tonic_std', 'EDA_tonic_min', 'EDA_tonic_max', 'ECG_mean',\n",
      "       'ECG_std', 'ECG_min', 'ECG_max', 'HR_mean', 'HR_std', 'HR_min',\n",
      "       'HR_max', 'EMG_mean', 'EMG_std', 'EMG_min', 'EMG_max', 'Temp_mean',\n",
      "       'Temp_std', 'Temp_min', 'Temp_max', 'Temp_slope_mean', 'Temp_slope_std',\n",
      "       'Temp_slope_min', 'Temp_slope_max', 'Resp_mean', 'Resp_std', 'Resp_min',\n",
      "       'Resp_max', 'Resp_rate_mean', 'Resp_rate_std', 'Resp_rate_min',\n",
      "       'Resp_rate_max', '1', '2', '3', 'subject'],\n",
      "      dtype='object')\n",
      "Índices en counts: [1, 2, 3]\n",
      "Claves en int_to_label: dict_keys([1, 2, 3])\n",
      "Number of samples per class:\n",
      "baseline: 34337\n",
      "stress: 19047\n",
      "amusement: 10264\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "combine_files(subject_ids)\n",
    "print('Processing complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WESAD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
