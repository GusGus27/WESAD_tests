{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "#import cupy as cp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.signal as scisig\n",
    "import scipy.stats\n",
    "from scipy.interpolate import interp1d \n",
    "from collections import Counter\n",
    "import scipy.interpolate as interp\n",
    "#import cupyx.scipy.signal as cusig\n",
    "import neurokit2 as nk\n",
    "from scipy.signal import find_peaks, welch, butter, filtfilt, convolve\n",
    "from scipy.optimize import curve_fit\n",
    "#import cupyx.scipy.signal as cpysig\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faulthandler\n",
    "faulthandler.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_dict = {'ACC': 700, 'ECG': 700, 'EMG': 700, 'EDA': 700, 'Temp': 700, 'Resp': 700, 'label': 700}\n",
    "WINDOW_IN_SECONDS = 60\n",
    "STRIDE_IN_SECONDS = 0.25\n",
    "label_dict = {'baseline': 1, 'stress': 2, 'amusement': 3}\n",
    "int_to_label = {1: 'baseline', 2: 'stress', 3: 'amusement'}\n",
    "feat_names = None\n",
    "DATA_PATH = r'WESAD/'\n",
    "SAVE_PATH = r'WESAD_DATA_60_025/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SAVE_PATH):\n",
    "    os.makedirs(SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def eda_stats(y):\n",
    "#    Fs = fs_dict['EDA']\n",
    "#    yn = (y - y.mean()) / y.std()\n",
    "#    print(yn)\n",
    "#    print(\"calculating eda stats\")\n",
    "#    [r, p, t, l, d, e, obj] = cvxEDA.cvxEDA(yn, 1. / Fs)\n",
    "#    return [r, p, t, l, d, e, obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_eda_metrics(eda_signal, fs, show_plots=False):\n",
    "    eda_signal = np.array(eda_signal).flatten()\n",
    "    \n",
    "    if len(eda_signal) < 2:\n",
    "        return [np.nan] * 16  # Retorna 16 NaNs si la señal no es válida\n",
    "\n",
    "    # --------- Señal total (EDA) ----------\n",
    "    eda_mean = np.mean(eda_signal)\n",
    "    eda_std = np.std(eda_signal)\n",
    "    eda_min = np.min(eda_signal)\n",
    "    eda_max = np.max(eda_signal)\n",
    "    eda_range = eda_max - eda_min\n",
    "    eda_slope = (eda_signal[-1] - eda_signal[0]) / len(eda_signal)\n",
    "\n",
    "    # --------- Estimación de componentes ----------\n",
    "    # Estimación de componente tónica (SCL): suavizado con ventana larga (10s)\n",
    "    win_scl = int(fs * 10)\n",
    "    kernel = np.ones(win_scl) / win_scl\n",
    "    scl = convolve(eda_signal, kernel, mode='same', method='auto')\n",
    "\n",
    "    # Estimación de componente fásica (SCR): diferencia entre señal y SCL\n",
    "    scr = eda_signal - scl\n",
    "\n",
    "    # --------- Métricas SCL ----------\n",
    "    scl_mean = np.mean(scl)\n",
    "    scl_std = np.std(scl)\n",
    "    \n",
    "    time = np.arange(len(scl)) / fs\n",
    "    corr_SCL_t = np.corrcoef(time, scl)[0, 1] if len(scl) > 1 else 0\n",
    "    corr_SCL_t = np.nan_to_num(corr_SCL_t)\n",
    "\n",
    "    # --------- Detección de picos SCR ----------\n",
    "    scr_peaks, _ = find_peaks(scr, height=0.01, prominence=0.05, distance=int(1.0 * fs))  # Ajustable\n",
    "    scr_values = scr[scr_peaks] if len(scr_peaks) > 0 else np.array([np.nan])\n",
    "    \n",
    "    scr_count = len(scr_peaks)\n",
    "\n",
    "    scr_mean = np.nanmean(scr_values) if scr_count > 0 else 0\n",
    "    scr_std = np.nanstd(scr_values) if scr_count > 0 else 0\n",
    "    scr_amp = np.nanmax(scr_values) if scr_count > 0 else 0\n",
    "    scr_sum = np.nansum(scr_values) if scr_count > 0 else 0\n",
    "    scr_area = np.trapz(scr_values, dx=1/fs) if scr_count > 1 else 0\n",
    "\n",
    "    if show_plots:\n",
    "        scr_norm = (scr - np.mean(scr)) / np.std(scr)\n",
    "        start_sec = 5\n",
    "        end_sec = 60\n",
    "        zoom_start = int(start_sec * fs)\n",
    "        zoom_end = int(end_sec * fs)\n",
    "\n",
    "        fig, axs = plt.subplots(3, 1, figsize=(14, 10))\n",
    "        fig.suptitle(\"Análisis de EDA y detección de picos SCR\", fontsize=16)\n",
    "\n",
    "        # 1. Señal completa\n",
    "        axs[0].plot(eda_signal, label='EDA Filtrada', linewidth=1)\n",
    "        axs[0].plot(scl, label='SCL (Tónica)', linewidth=1)\n",
    "        axs[0].plot(scr, label='SCR (Fásica)', linewidth=1)\n",
    "        axs[0].scatter(scr_peaks, scr[scr_peaks], c='red', label='SCR Peaks')\n",
    "        axs[0].set_title(\"Señal completa con componentes\")\n",
    "        axs[0].legend()\n",
    "        axs[0].grid(True)\n",
    "\n",
    "        # 2. SCR normalizada\n",
    "        axs[1].plot(scr_norm, color='green', label='SCR Normalizada')\n",
    "        axs[1].scatter(scr_peaks, scr_norm[scr_peaks], c='red', label='Picos detectados')\n",
    "        axs[1].axhline(0, color='gray', linestyle='--', linewidth=0.5)\n",
    "        axs[1].set_title(\"SCR Normalizada\")\n",
    "        axs[1].legend()\n",
    "        axs[1].grid(True)\n",
    "\n",
    "        # 3. Zoom en una región\n",
    "        zoom_peaks = [p for p in scr_peaks if zoom_start <= p < zoom_end]\n",
    "        #axs[2].plot(eda_signal[zoom_start:zoom_end], label='EDA')\n",
    "        #axs[2].plot(scl[zoom_start:zoom_end], label='SCL')\n",
    "        axs[2].plot(scr[zoom_start:zoom_end], label='SCR')\n",
    "        axs[2].scatter(\n",
    "            [p - zoom_start for p in zoom_peaks],\n",
    "            [scr[p] for p in zoom_peaks],\n",
    "            c='red', label='SCR Peaks'\n",
    "        )\n",
    "        axs[2].set_title(f\"Zoom: muestras {zoom_start} a {zoom_end}\")\n",
    "        axs[2].legend()\n",
    "        axs[2].grid(True)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "    return eda_mean, eda_std, eda_min, eda_max, eda_range, eda_slope, scl_mean, scl_std, scr_mean, scr_std, corr_SCL_t, scr_count, scr_amp, scr_sum, scr_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emg_features(emg_signal, fs, show_plots=False):\n",
    "    emg_signal = np.array(emg_signal).flatten()\n",
    "\n",
    "    # --- Estadísticos de la señal cruda ---\n",
    "    emg_mean = np.mean(emg_signal)\n",
    "    emg_std = np.std(emg_signal)\n",
    "    emg_median = np.median(emg_signal)\n",
    "    emg_p10 = np.percentile(emg_signal, 10)\n",
    "    emg_p90 = np.percentile(emg_signal, 90)\n",
    "    emg_range = np.max(emg_signal) - np.min(emg_signal)\n",
    "    emg_sum = np.sum(emg_signal)\n",
    "\n",
    "    # --- Espectro de potencia ---\n",
    "    fxx, pxx = scisig.welch(emg_signal, fs=fs, nperseg=1024)\n",
    "    f_peak = fxx[np.argmax(pxx)]\n",
    "\n",
    "    psd_bands = [\n",
    "        np.trapz(pxx[(fxx >= 0) & (fxx < 10)]),\n",
    "        np.trapz(pxx[(fxx >= 10) & (fxx < 20)]),\n",
    "        np.trapz(pxx[(fxx >= 20) & (fxx < 50)]),\n",
    "        np.trapz(pxx[(fxx >= 50) & (fxx < 100)]),\n",
    "        np.trapz(pxx[(fxx >= 100) & (fxx < 150)]),\n",
    "        np.trapz(pxx[(fxx >= 150) & (fxx < 250)]),\n",
    "        np.trapz(pxx[(fxx >= 250) & (fxx < 350)])\n",
    "    ]\n",
    "    psd_total = sum(psd_bands)\n",
    "    psd_rel = [band / psd_total if psd_total > 0 else 0 for band in psd_bands]\n",
    "\n",
    "    # --- Detección de picos ---\n",
    "    threshold = np.mean(emg_signal) + 2 * np.std(emg_signal)\n",
    "    peak_indices, _ = scisig.find_peaks(emg_signal, height=threshold)\n",
    "    peak_values = emg_signal[peak_indices] if len(peak_indices) > 0 else np.array([0])\n",
    "    \n",
    "    peak_count = len(peak_indices)\n",
    "    peak_amp_mean = np.mean(peak_values)\n",
    "    peak_amp_std = np.std(peak_values)\n",
    "    peak_amp_sum = np.sum(peak_values)\n",
    "    peak_amp_norm = peak_amp_sum / len(emg_signal)\n",
    "\n",
    "    # --- Gráfica opcional ---\n",
    "    if show_plots:\n",
    "        time = np.arange(len(emg_signal)) / fs\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(time, emg_signal, label='EMG Signal')\n",
    "        plt.plot(time[peak_indices], emg_signal[peak_indices], 'rx', label='Detected Peaks')\n",
    "        plt.axhline(y = threshold, color='gray', linestyle='--', label='Mean + STD')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Amplitude')\n",
    "        plt.title('EMG Signal with Detected Peaks')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return emg_mean, emg_std, emg_median, emg_p10, emg_p90, emg_range, emg_sum, f_peak, *psd_rel, peak_count, peak_amp_mean, peak_amp_std, peak_amp_sum, peak_amp_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hrv_metrics(ecg_signal, fs, show_plots=False):\n",
    "    ecg_signal = np.array(ecg_signal).flatten()\n",
    "    \n",
    "    # Detección de picos R mejorada\n",
    "    peaks, _ = scisig.find_peaks(ecg_signal, distance=fs*0.4, height=np.mean(ecg_signal) + np.std(ecg_signal))\n",
    "\n",
    "    if len(peaks) < 2:\n",
    "        return 0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "    # Cálculo de intervalos RR\n",
    "    rr_intervals = np.diff(peaks) * (1000 / fs)  # Convertir a milisegundos\n",
    "    rr_intervals = rr_intervals[(rr_intervals > 400) & (rr_intervals < 1500)]  # Filtro fisiológico\n",
    "\n",
    "    if len(rr_intervals) < 2:\n",
    "        return 0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "\n",
    "    hr_mean = 60000 / np.mean(rr_intervals) if len(rr_intervals) > 0 else np.nan\n",
    "    hr_std = np.std(60000 / rr_intervals) if len(rr_intervals) > 0 else np.nan\n",
    "\n",
    "    # Features temporales\n",
    "    nn50 = np.sum(np.abs(np.diff(rr_intervals)) > 50)\n",
    "    pnn50 = (nn50 / len(rr_intervals)) * 100 if len(rr_intervals) > 0 else np.nan\n",
    "    rms_hrv = np.sqrt(np.mean(np.square(np.diff(rr_intervals))))\n",
    "\n",
    "    # Cálculo de TINN\n",
    "    hist, bin_edges = np.histogram(rr_intervals, bins='auto')\n",
    "    tinn = bin_edges[np.argmax(hist)] if len(hist) > 0 else np.nan\n",
    "\n",
    "    # Interpolación mejorada\n",
    "    time_rr = np.cumsum(rr_intervals) / 1000\n",
    "    time_rr = time_rr - time_rr[0]  # Normalizar inicio en 0\n",
    "\n",
    "    fs_resample = 4.0  # Frecuencia de resampleo\n",
    "    time_resampled = np.arange(0, time_rr[-1], 1 / fs_resample)\n",
    "    interp_func = interp1d(time_rr, rr_intervals, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "    rr_resampled = interp_func(time_resampled)\n",
    "\n",
    "    # Análisis espectral (PSD)\n",
    "    fxx, pxx = scisig.welch(rr_resampled, fs=fs_resample, nperseg=min(len(rr_resampled), 256))\n",
    "    lf_band, hf_band = (0.04, 0.15), (0.15, 0.4)\n",
    "\n",
    "    lf_mask = (fxx >= lf_band[0]) & (fxx <= lf_band[1])\n",
    "    hf_mask = (fxx >= hf_band[0]) & (fxx <= hf_band[1])\n",
    "\n",
    "    lf = np.trapz(pxx[lf_mask], fxx[lf_mask]) if np.any(lf_mask) else np.nan\n",
    "    hf = np.trapz(pxx[hf_mask], fxx[hf_mask]) if np.any(hf_mask) else np.nan\n",
    "    lf_hf_ratio = lf / hf if (hf > 0 and not np.isnan(hf)) else np.nan\n",
    "\n",
    "    sum_f = np.trapz(pxx, fxx)\n",
    "    rel_f = (lf + hf) / sum_f if sum_f > 0 else np.nan\n",
    "    lf_norm = (lf / (lf + hf)) * 100 if (lf + hf) > 0 else np.nan\n",
    "    hf_norm = (hf / (lf + hf)) * 100 if (lf + hf) > 0 else np.nan\n",
    "\n",
    "    if show_plots:\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(ecg_signal, label=\"ECG\", color='gray')\n",
    "        plt.scatter(peaks, ecg_signal[peaks], color=\"red\", label=\"Picos R\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Detección de Picos R en ECG\")\n",
    "        plt.xlabel(\"Tiempo (ms)\")\n",
    "        plt.ylabel(\"Amplitud\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(time_rr, rr_intervals, \"o-\", label=\"Original RR\")\n",
    "        plt.plot(time_resampled, rr_resampled, \"x-\", label=\"Interpolado\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Interpolación de RR intervals\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.semilogy(fxx, pxx)  # Usa escala logarítmica\n",
    "        plt.axvspan(0.04, 0.15, color=\"blue\", alpha=0.3, label=\"LF Band\")\n",
    "        plt.axvspan(0.15, 0.4, color=\"red\", alpha=0.3, label=\"HF Band\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Espectro HRV\")\n",
    "        plt.xlabel(\"Frecuencia (Hz)\")\n",
    "        plt.ylabel(\"PSD\")\n",
    "        plt.show()\n",
    "\n",
    "    return hr_mean, hr_std, nn50, pnn50, tinn, rms_hrv, lf, hf, lf_hf_ratio, sum_f, rel_f, lf_norm, hf_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emg_peaks(emg_signal, threshold=0.05):\n",
    "    # Normalizar señal EMG\n",
    "    emg_signal = emg_signal.flatten()\n",
    "    emg_signal = (emg_signal - np.min(emg_signal)) / (np.max(emg_signal) - np.min(emg_signal))\n",
    "\n",
    "    # Detectar picos que superen el umbral\n",
    "    peaks, _ = scisig.find_peaks(emg_signal, height=threshold)\n",
    "    \n",
    "    # Obtener amplitudes de los picos detectados\n",
    "    peak_amplitudes = emg_signal[peaks] if len(peaks) > 0 else [0]\n",
    "\n",
    "    return len(peaks), np.mean(peak_amplitudes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_respiration_metrics(resp_signal, fs, show_plots=False):\n",
    "    resp_signal = np.array(resp_signal).flatten()\n",
    "    peaks, _ = scisig.find_peaks(resp_signal, distance=fs * 0.3)\n",
    "    troughs, _ = scisig.find_peaks(-resp_signal, distance=fs * 0.3)\n",
    "    \n",
    "    if len(peaks) < 2 or len(troughs) < 2:\n",
    "        return 0, 0, 0, 0, 0, 0, 0, 0, 0\n",
    "\n",
    "    inspiration_durations = np.diff(peaks) / fs\n",
    "    expiration_durations = np.diff(troughs) / fs\n",
    "\n",
    "    I_mean = np.mean(inspiration_durations)\n",
    "    I_std = np.std(inspiration_durations)\n",
    "    E_mean = np.mean(expiration_durations)\n",
    "    E_std = np.std(expiration_durations)\n",
    "\n",
    "    ie_ratio = I_mean / E_mean if E_mean > 0 else 0\n",
    "    resp_range = np.max(resp_signal) - np.min(resp_signal)\n",
    "    insp_vol = np.mean(resp_signal[peaks]) - np.mean(resp_signal[troughs])\n",
    "    resp_rate = len(peaks) / (len(resp_signal) / fs)\n",
    "    resp_duration = len(resp_signal) / fs\n",
    "\n",
    "    if show_plots:\n",
    "        plt.plot(resp_signal, label=\"Señal Respiratoria\")\n",
    "        plt.scatter(peaks, resp_signal[peaks], color='red', label=\"Picos\")\n",
    "        plt.scatter(troughs, resp_signal[troughs], color='blue', label=\"Valles\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return I_mean, I_std, E_mean, E_std, ie_ratio, resp_range, insp_vol, resp_rate, resp_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubjectData:\n",
    "\n",
    "    def __init__(self, main_path, subject_number):\n",
    "        self.name = f'S{subject_number}'\n",
    "        self.subject_keys = ['signal', 'label', 'subject']\n",
    "        self.signal_keys = ['chest', 'wrist']\n",
    "        self.chest_keys = ['ACC', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp']\n",
    "        self.wrist_keys = ['ACC', 'BVP', 'EDA', 'TEMP']\n",
    "        with open(os.path.join(main_path, self.name) + '/' + self.name + '.pkl', 'rb') as file:\n",
    "            self.data = pickle.load(file, encoding='latin1')\n",
    "        self.labels = pd.DataFrame(self.data['label'], columns=[\"label\"])\n",
    "\n",
    "    def get_wrist_data(self):\n",
    "        data = self.data['signal']['wrist']\n",
    "        data.update({'Resp': self.data['signal']['chest']['Resp']})\n",
    "        return data\n",
    "\n",
    "    def get_chest_data(self):\n",
    "        tmp = self.data['signal']['chest']\n",
    "        acc = tmp[\"ACC\"]\n",
    "        tmp_acc = pd.DataFrame(acc, columns=[\"ACC_X\", \"ACC_Y\", \"ACC_Z\"])\n",
    "\n",
    "        tmp_other = pd.DataFrame({\n",
    "            \"ECG\": tmp[\"ECG\"].ravel(),\n",
    "            \"EMG\": tmp[\"EMG\"].ravel(),\n",
    "            \"EDA\": tmp[\"EDA\"].ravel(),\n",
    "            \"Temp\": tmp[\"Temp\"].ravel(),\n",
    "            \"Resp\": tmp[\"Resp\"].ravel()\n",
    "        })\n",
    "\n",
    "        df = pd.concat([tmp_acc, tmp_other], axis=1)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def extract_features(self):  # only wrist\n",
    "        results = \\\n",
    "            {\n",
    "                key: get_statistics(self.get_chest_data()[key].flatten(), self.labels, key)\n",
    "                for key in self.chest_keys\n",
    "            }\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_filter(data, cutoff, fs, order=4, filter_type='low'):\n",
    "    \"\"\"\n",
    "    Aplica un filtro Butterworth a los datos.\n",
    "\n",
    "    Parámetros:\n",
    "    - data: array de la señal a filtrar.\n",
    "    - cutoff: frecuencia de corte (o tupla en caso de bandpass).\n",
    "    - fs: frecuencia de muestreo.\n",
    "    - order: orden del filtro.\n",
    "    - filter_type: 'low', 'high' o 'band'.\n",
    "\n",
    "    Retorna:\n",
    "    - Señal filtrada.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs  # Frecuencia de Nyquist\n",
    "\n",
    "    # Normalizar la frecuencia de corte\n",
    "    if isinstance(cutoff, (list, tuple)):  # Band-pass o Band-stop\n",
    "        normal_cutoff = [c / nyq for c in cutoff]\n",
    "    else:  # Low-pass o High-pass\n",
    "        normal_cutoff = cutoff / nyq\n",
    "\n",
    "    # Crear el filtro Butterworth\n",
    "    b, a = scisig.butter(order, normal_cutoff, btype=filter_type, analog=False)\n",
    "\n",
    "    # Aplicar el filtro con filtfilt para evitar desfases\n",
    "    return scisig.filtfilt(b, a, np.array(data))\n",
    "\n",
    "\n",
    "def get_slope(signal):\n",
    "    if len(signal) < 2:  # Evita divisiones por 0 o valores no válidos\n",
    "        return 0\n",
    "    \n",
    "    # Convertir a pandas.Series si es necesario\n",
    "    if not isinstance(signal, pd.Series):\n",
    "        signal = pd.Series(signal)\n",
    "\n",
    "    resu = (signal.iloc[-1] - signal.iloc[0]) / (len(signal) - 1)  # Evita dividir entre len(signal)\n",
    "\n",
    "    # Convertir a escalar si es un array\n",
    "    if isinstance(resu, np.ndarray):\n",
    "        resu = resu.flatten()[0]\n",
    "    \n",
    "    return resu\n",
    "\n",
    "def get_peak_freq(x, fs):\n",
    "    f, Pxx = scisig.periodogram(x, fs=fs)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    return psd_dict[max(psd_dict.keys())]\n",
    "\n",
    "def get_window_stats(data, label=-1):\n",
    "    mean_features = np.mean(data)\n",
    "    std_features = np.std(data)\n",
    "    min_features = np.amin(data)\n",
    "    max_features = np.amax(data)\n",
    "\n",
    "    features = {'mean': mean_features, 'std': std_features, 'min': min_features, 'max': max_features,\n",
    "                'label': label}\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_net_accel(data):\n",
    "    return (data['ACC_x'] ** 2 + data['ACC_y'] ** 2 + data['ACC_z'] ** 2).apply(lambda x: np.sqrt(x))\n",
    "\n",
    "\n",
    "def get_peak_freq(x):\n",
    "    f, Pxx = scisig.periodogram(x, fs=8)\n",
    "    psd_dict = {amp: freq for amp, freq in zip(Pxx, f)}\n",
    "    peak_freq = psd_dict[max(psd_dict.keys())]\n",
    "    return peak_freq\n",
    "\n",
    "\n",
    "# https://github.com/MITMediaLabAffectiveComputing/eda-explorer/blob/master/AccelerometerFeatureExtractionScript.py\n",
    "def filterSignalFIR(eda, cutoff=0.4, numtaps=64):\n",
    "    f = cutoff / (fs_dict['ACC'] / 2.0)\n",
    "    FIR_coeff = scisig.firwin(numtaps, f)\n",
    "\n",
    "    return scisig.lfilter(FIR_coeff, 1, eda.flatten())\n",
    "\n",
    "\n",
    "def triangle(x, a, b, c):\n",
    "    return np.maximum(0, a - np.abs(x - b) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(data_dict, fs_dict):\n",
    "    feature_dict = {}\n",
    "\n",
    "    # ECG y BVP\n",
    "    ecg_signal = data_dict['ECG']\n",
    "    eda_signal = data_dict['EDA']\n",
    "    emg_signal = data_dict['EMG']\n",
    "    resp_signal = data_dict['Resp']\n",
    "    temp_signal = data_dict['Temp']\n",
    "    \n",
    "    hr_mean, hr_std, nn50, pNN50, tinn, rmsHRV, lf, hf, lf_hf, sum_f, rel_f, lf_norm, hf_norm = compute_hrv_metrics(ecg_signal, fs_dict['ECG'])\n",
    "\n",
    "    feature_dict.update({\n",
    "        'HR_mean': hr_mean, 'HR_std' : hr_std,\n",
    "        'NN50': nn50, 'pNN50': pNN50, 'TINN': tinn, \n",
    "        'rmsHRV': rmsHRV, 'LF': lf, 'HF': hf, 'LF_HF': lf_hf,\n",
    "        'sum_f': sum_f, 'rel_f': rel_f, 'LF_norm': lf_norm, 'HF_norm': hf_norm\n",
    "    })\n",
    "\n",
    "    eda_mean, eda_std, eda_min, eda_max, eda_range, eda_slope, scl_mean, scl_std, scr_mean, scr_std, corr_scl_t, scr_count, scr_amp, scr_sum, scr_area = compute_eda_metrics(eda_signal, fs_dict['EDA'])\n",
    "\n",
    "    feature_dict.update({\n",
    "        'EDA_mean': eda_mean, 'EDA_std': eda_std,\n",
    "        'EDA_min': eda_min, 'EDA_max': eda_max,\n",
    "        'EDA_range': eda_range, 'EDA_slope': eda_slope,\n",
    "        'scl_mean': scl_mean, 'scl_std': scl_std, 'scr_mean': scr_mean, 'scr_std': scr_std,\n",
    "        'corr_scl_t': corr_scl_t, 'scr_count': scr_count, 'scr_amp': scr_amp,\n",
    "        'scr_sum': scr_sum, 'scr_area': scr_area\n",
    "    })\n",
    "\n",
    "\n",
    "    emg_features = compute_emg_features(emg_signal, fs_dict['EMG'])\n",
    "    feature_dict.update({\n",
    "        'EMG_mean': emg_features[0],\n",
    "        'EMG_std': emg_features[1],\n",
    "        'EMG_median': emg_features[2],\n",
    "        'EMG_p10': emg_features[3],\n",
    "        'EMG_p90': emg_features[4],\n",
    "        'EMG_range': emg_features[5],\n",
    "        'EMG_sum': emg_features[6],\n",
    "        'EMG_f_peak': emg_features[7],\n",
    "        'EMG_psd_0_10Hz': emg_features[8],\n",
    "        'EMG_psd_10_20Hz': emg_features[9],\n",
    "        'EMG_psd_20_50Hz': emg_features[10],\n",
    "        'EMG_psd_50_100Hz': emg_features[11],\n",
    "        'EMG_psd_100_150Hz': emg_features[12],\n",
    "        'EMG_psd_150_250Hz': emg_features[13],\n",
    "        'EMG_psd_250_350Hz': emg_features[14],\n",
    "        'EMG_peak_count': emg_features[15],\n",
    "        'EMG_peak_amp_mean': emg_features[16],\n",
    "        'EMG_peak_amp_std': emg_features[17],\n",
    "        'EMG_peak_amp_sum': emg_features[18],\n",
    "        'EMG_peak_amp_norm': emg_features[19]\n",
    "    })\n",
    "\n",
    "\n",
    "    feature_dict.update({\n",
    "        'Resp_mean': np.mean(resp_signal), 'Resp_std': np.std(resp_signal),\n",
    "    })\n",
    "\n",
    "    I_mean, I_std, E_mean, E_std, ie_ratio, resp_range, insp_vol, resp_rate, resp_duration = compute_respiration_metrics(resp_signal, fs_dict['Resp'])\n",
    "              \n",
    "    feature_dict.update({\n",
    "        'Resp_I_mean': I_mean, 'Resp_I_std': I_std, 'Resp_E_mean': E_mean, 'Resp_E_std': E_std,\n",
    "        'Resp_IE_ratio': ie_ratio, 'Resp_range': resp_range, 'Resp_insp_vol': insp_vol,\n",
    "        'Resp_rate': resp_rate, 'Resp_duration': resp_duration\n",
    "    })\n",
    "\n",
    "    # Temperatura\n",
    "    feature_dict.update({\n",
    "        'Temp_mean': np.mean(temp_signal), 'Temp_std': np.std(temp_signal),\n",
    "        'Temp_min': np.min(temp_signal), 'Temp_max': np.max(temp_signal),\n",
    "        'Temp_range': np.max(temp_signal) - np.min(temp_signal), 'Temp_slope': get_slope(temp_signal)\n",
    "    })\n",
    "\n",
    "    # Convertir a DataFrame con solo una fila\n",
    "    df = pd.DataFrame([feature_dict])\n",
    "\n",
    "    df[\"EDA_slope\"] = df[\"EDA_slope\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "    df[\"Temp_slope\"] = df[\"Temp_slope\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(data_dict, labels_df, fs_dict, stride_seconds):\n",
    "    global feat_names\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    samples = []\n",
    "    all_samples = []\n",
    "\n",
    "    labels = labels_df['label'] \n",
    "    \n",
    "    # Convertir tiempo a muestras\n",
    "    window_len = int(fs_dict['ECG'] * WINDOW_IN_SECONDS)  # Se toma una señal como referencia\n",
    "    stride_len = int(fs_dict['ECG'] * stride_seconds)  \n",
    "\n",
    "    num_ventanas = (len(labels) - window_len) // stride_len + 1\n",
    "    print(f\"El número de ventanas esperadas es: {num_ventanas}\")\n",
    "\n",
    "    last_progress = -10\n",
    "    processed = 0\n",
    "\n",
    "    all_samples = pd.DataFrame()\n",
    "\n",
    "    for start in range(0, len(labels) - window_len + 1, stride_len):\n",
    "        end = start + window_len\n",
    "\n",
    "        processed += 1  # Incrementar contador manualmente\n",
    "        progress = processed / num_ventanas * 100\n",
    "\n",
    "        if processed % 500 == 0:\n",
    "            gc.collect()\n",
    "\n",
    "        if processed % 50 == 0:\n",
    "\n",
    "            print(f\"\\rProgreso: {progress:.4f}% completado\", end=\"\", flush=True)\n",
    "\n",
    "        # Extraer ventana de cada señal\n",
    "        #print(f\"\\nVentana {start} - {end} - Numero {processed}\", end=\"\", flush= True)\n",
    "        window_data = {key: val[start:end] for key, val in data_dict.items()}\n",
    "        window_labels = labels[start:end]  # Extraer etiquetas de la ventana\n",
    "\n",
    "        # Aplicar hard labeling: etiqueta más frecuente en la ventana\n",
    "        label_counts = Counter(window_labels)\n",
    "        most_common_labels = label_counts.most_common()  # [(label1, count1), (label2, count2), ...]\n",
    "        \n",
    "        # Si hay empate, tomar la primera que aparece en la ventana original\n",
    "        max_count = most_common_labels[0][1]\n",
    "        candidate_labels = [label for label, count in most_common_labels if count == max_count]\n",
    "        chosen_label = next(label for label in window_labels if label in candidate_labels)\n",
    "\n",
    "        features_df = compute_features(window_data, fs_dict)\n",
    "\n",
    "        # Agregar la etiqueta al DataFrame de features\n",
    "        features_df['label'] = chosen_label\n",
    "\n",
    "        all_samples = pd.concat([all_samples, features_df], ignore_index=True)\n",
    "\n",
    "    if all_samples.empty:\n",
    "        print(\"Advertencia: No se generaron muestras en get_samples(), devolviendo DataFrame vacío.\")\n",
    "\n",
    "    print(\"\\n Procesamiento de ventanas completado.\")  \n",
    "    \n",
    "    return all_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_patient_data(subject_id):\n",
    "    global SAVE_PATH\n",
    "    global WINDOW_IN_SECONDS\n",
    "\n",
    "    subject = SubjectData(main_path=DATA_PATH, subject_number=subject_id)\n",
    "\n",
    "    # Obtener datos del pecho (ahora en DataFrame)\n",
    "    data_df = subject.get_chest_data()\n",
    "\n",
    "\n",
    "    print(\"Columnas disponibles:\", data_df.columns)\n",
    "    print(\"Etiquetas:\", subject.labels.value_counts())\n",
    "\n",
    "    # Definir clases de interés\n",
    "    valid_labels = {1, 2, 3}\n",
    "    \n",
    "    # Filtrar datos válidos\n",
    "    mask = subject.labels['label'].isin(valid_labels)\n",
    "    filtered_labels = subject.labels[mask].reset_index(drop=True)\n",
    "    filtered_data = data_df[mask].reset_index(drop=True)\n",
    "\n",
    "    filtered_data = filtered_data.copy()\n",
    "    \n",
    "    filtered_data['EDA'] = butter_filter(filtered_data['EDA'], cutoff=5, fs=fs_dict['EDA'], order=4, filter_type='low')\n",
    "    filtered_data['EMG'] = butter_filter(filtered_data['EMG'], cutoff=50, fs=fs_dict['EMG'], order=4, filter_type='low')\n",
    "    filtered_data['Resp'] = butter_filter(filtered_data['Resp'], cutoff=(0.1, 0.35), fs=fs_dict['Resp'], order=2, filter_type='band')\n",
    "\n",
    "    print(\"Data lista para procesar: \" + str(len(filtered_labels)))\n",
    "\n",
    "\n",
    "    samples = get_samples(filtered_data, filtered_labels, fs_dict=fs_dict, stride_seconds=STRIDE_IN_SECONDS)\n",
    "\n",
    "    print(\"Características calculadas\")\n",
    "\n",
    "    if not isinstance(samples, pd.DataFrame):\n",
    "        all_samples = pd.concat(samples, ignore_index=True)\n",
    "    else:\n",
    "        all_samples = samples.copy()\n",
    "\n",
    "    all_samples['label'] = all_samples['label'].astype(int)\n",
    "    all_samples = pd.concat([all_samples.drop('label', axis=1), pd.get_dummies(all_samples['label'])], axis=1)\n",
    "\n",
    "    # Guardar como CSV\n",
    "    all_samples.to_csv(f'{SAVE_PATH}/{subject_id}_features.csv', index=False)\n",
    "\n",
    "    # **Liberar memoria**\n",
    "    del subject, all_samples, samples, data_df, filtered_data, filtered_labels\n",
    "    gc.collect()  # Forzar recolección de basura\n",
    "    samples = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(subjects):\n",
    "    df_list = []\n",
    "    for s in subjects:\n",
    "        df = pd.read_csv(f'{SAVE_PATH}/{s}_features.csv')\n",
    "        df['subject'] = s\n",
    "        df_list.append(df)\n",
    "\n",
    "    df = pd.concat(df_list)\n",
    "\n",
    "    print(df.head(10))\n",
    "    print(df.columns)\n",
    "\n",
    "    df[['1', '2', '3']] = df[['1', '2', '3']].fillna(0).astype(int)\n",
    "    df[['1', '2', '3']] = df[['1', '2', '3']].astype(int)\n",
    "    df['label'] = df[['1', '2', '3']].idxmax(axis=1).astype(int)\n",
    "    df.drop(['1', '2', '3'], axis=1, inplace=True)\n",
    "\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    df.to_csv(f'{SAVE_PATH}/features.csv')\n",
    "\n",
    "    counts = df['label'].value_counts()\n",
    "\n",
    "    print(\"Índices en counts:\", counts.index.tolist())\n",
    "    print(\"Claves en int_to_label:\", int_to_label.keys())\n",
    "\n",
    "    print('Number of samples per class:')\n",
    "    for label, number in zip(counts.index, counts.values):\n",
    "        print(f'{int_to_label[label]}: {number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for S2...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        2142701\n",
      "1         800800\n",
      "4         537599\n",
      "2         430500\n",
      "3         253400\n",
      "6          45500\n",
      "7          44800\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1484700\n",
      "El número de ventanas esperadas es: 8245\n",
      "Progreso: 99.4542% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S3...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        2345699\n",
      "1         798000\n",
      "4         546001\n",
      "2         448000\n",
      "3         262500\n",
      "5          51100\n",
      "6          46900\n",
      "7          46900\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1508500\n",
      "El número de ventanas esperadas es: 8381\n",
      "Progreso: 99.6301% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S4...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        2314199\n",
      "1         810601\n",
      "4         563500\n",
      "2         444500\n",
      "3         260400\n",
      "7          36401\n",
      "5          35699\n",
      "6          30800\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1515501\n",
      "El número de ventanas esperadas es: 8421\n",
      "Progreso: 99.7506% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S5...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        2142700\n",
      "1         838600\n",
      "4         555800\n",
      "2         451500\n",
      "3         261800\n",
      "5          50401\n",
      "7          49000\n",
      "6          30799\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1551900\n",
      "El número de ventanas esperadas es: 8629\n",
      "Progreso: 99.6639% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S6...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        2733499\n",
      "1         826000\n",
      "4         550900\n",
      "2         455000\n",
      "3         260400\n",
      "7          48300\n",
      "5          40600\n",
      "6          35001\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1541400\n",
      "El número de ventanas esperadas es: 8569\n",
      "Progreso: 99.7783% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S7...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1472098\n",
      "1         830200\n",
      "4         553001\n",
      "2         448000\n",
      "3         260401\n",
      "7          37101\n",
      "5          35000\n",
      "6          30799\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1538601\n",
      "El número de ventanas esperadas es: 8553\n",
      "Progreso: 99.9649% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S8...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1616300\n",
      "1         818300\n",
      "4         557200\n",
      "2         469000\n",
      "3         258999\n",
      "7          36400\n",
      "6          35701\n",
      "5          34300\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1546299\n",
      "El número de ventanas esperadas es: 8596\n",
      "Progreso: 99.4649% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S9...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1435700\n",
      "1         826000\n",
      "4         555100\n",
      "2         451500\n",
      "3         260400\n",
      "6          43400\n",
      "5          42000\n",
      "7          42000\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1537900\n",
      "El número de ventanas esperadas es: 8549\n",
      "Progreso: 99.4268% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S10...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1589000\n",
      "1         826000\n",
      "4         557200\n",
      "2         507500\n",
      "3         260400\n",
      "7          39900\n",
      "5          35700\n",
      "6          31500\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1593900\n",
      "El número de ventanas esperadas es: 8869\n",
      "Progreso: 99.7858% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S11...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1443400\n",
      "1         826000\n",
      "4         553701\n",
      "2         476000\n",
      "3         257600\n",
      "6          36399\n",
      "5          35000\n",
      "7          35000\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1559600\n",
      "El número de ventanas esperadas es: 8673\n",
      "Progreso: 99.7348% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S13...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1679300\n",
      "1         826001\n",
      "4         556499\n",
      "2         464800\n",
      "3         267400\n",
      "5          34300\n",
      "6          33600\n",
      "7          14000\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1558201\n",
      "El número de ventanas esperadas es: 8665\n",
      "Progreso: 99.8269% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S14...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1648499\n",
      "1         826000\n",
      "4         555800\n",
      "2         472500\n",
      "3         260401\n",
      "5          44100\n",
      "6          38500\n",
      "7          37800\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1558901\n",
      "El número de ventanas esperadas es: 8669\n",
      "Progreso: 99.7808% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S15...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1457401\n",
      "1         822500\n",
      "4         555799\n",
      "2         480200\n",
      "3         260400\n",
      "5          35000\n",
      "6          32900\n",
      "7          32200\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1563100\n",
      "El número de ventanas esperadas es: 8693\n",
      "Progreso: 99.5053% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S16...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1717100\n",
      "1         826000\n",
      "4         554399\n",
      "2         471101\n",
      "3         257600\n",
      "6          39900\n",
      "5          38500\n",
      "7          37100\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1554701\n",
      "El número de ventanas esperadas es: 8645\n",
      "Progreso: 99.4795% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n",
      "Processing data for S17...\n",
      "Columnas disponibles: Index(['ACC_X', 'ACC_Y', 'ACC_Z', 'ECG', 'EMG', 'EDA', 'Temp', 'Resp'], dtype='object')\n",
      "Etiquetas: label\n",
      "0        1917301\n",
      "1         826700\n",
      "4         511700\n",
      "2         506100\n",
      "3         260400\n",
      "6          41299\n",
      "5          40600\n",
      "7          39900\n",
      "Name: count, dtype: int64\n",
      "Data lista para procesar: 1593200\n",
      "El número de ventanas esperadas es: 8865\n",
      "Progreso: 99.8308% completado\n",
      " Procesamiento de ventanas completado.\n",
      "Características calculadas\n"
     ]
    }
   ],
   "source": [
    "#subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "for patient in subject_ids:\n",
    "    print(f'Processing data for S{patient}...')\n",
    "    make_patient_data(patient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     HR_mean     HR_std  NN50      pNN50        TINN     rmsHRV           LF  \\\n",
      "0  80.696549   9.931009    17  21.518987  655.178571  61.766682  6836.774620   \n",
      "1  80.594867   9.915636    18  22.500000  655.178571  61.677656  6858.923359   \n",
      "2  80.594867   9.915636    18  22.500000  655.178571  61.677656  6858.923359   \n",
      "3  80.727963   9.906418    18  22.784810  655.178571  62.070924  6994.721115   \n",
      "4  80.529192   9.976642    19  23.750000  655.178571  62.198173  7015.619134   \n",
      "5  80.529192   9.976642    19  23.750000  655.178571  62.198173  7015.619134   \n",
      "6  80.657316   9.972152    19  24.050633  655.178571  62.407231  7123.762842   \n",
      "7  80.657316   9.972152    19  24.050633  655.178571  62.407231  7123.762842   \n",
      "8  80.394315  10.109708    19  23.750000  655.178571  62.251314  7137.272136   \n",
      "9  80.461721  10.148366    18  22.784810  655.178571  62.297080  7240.430642   \n",
      "\n",
      "            HF     LF_HF        sum_f  ...  Temp_mean  Temp_std   Temp_min  \\\n",
      "0   998.941320  6.844020  8791.542465  ...  29.156557  0.075281  28.954346   \n",
      "1  1006.989207  6.811318  8866.717929  ...  29.156010  0.076006  28.950043   \n",
      "2  1006.989207  6.811318  8866.717929  ...  29.155432  0.076751  28.950043   \n",
      "3   985.311458  7.098995  8930.497220  ...  29.154818  0.077507  28.947174   \n",
      "4   998.327482  7.027373  9027.897753  ...  29.154190  0.078276  28.939972   \n",
      "5   998.327482  7.027373  9027.897753  ...  29.153551  0.079065  28.939972   \n",
      "6   980.301486  7.266910  9059.914732  ...  29.152903  0.079853  28.939972   \n",
      "7   980.301486  7.266910  9059.914732  ...  29.152260  0.080588  28.935700   \n",
      "8   995.493537  7.169582  9162.136769  ...  29.151598  0.081353  28.935700   \n",
      "9   976.939344  7.411341  9216.520113  ...  29.150925  0.082120  28.935700   \n",
      "\n",
      "    Temp_max  Temp_range  Temp_slope     1      2      3  subject  \n",
      "0  29.426208    0.471863   -0.000002  True  False  False        2  \n",
      "1  29.426208    0.476166   -0.000003  True  False  False        2  \n",
      "2  29.426208    0.476166   -0.000003  True  False  False        2  \n",
      "3  29.426208    0.479034   -0.000004  True  False  False        2  \n",
      "4  29.426208    0.486237   -0.000003  True  False  False        2  \n",
      "5  29.426208    0.486237   -0.000004  True  False  False        2  \n",
      "6  29.426208    0.486237   -0.000004  True  False  False        2  \n",
      "7  29.426208    0.490509   -0.000004  True  False  False        2  \n",
      "8  29.426208    0.490509   -0.000004  True  False  False        2  \n",
      "9  29.426208    0.490509   -0.000004  True  False  False        2  \n",
      "\n",
      "[10 rows x 69 columns]\n",
      "Index(['HR_mean', 'HR_std', 'NN50', 'pNN50', 'TINN', 'rmsHRV', 'LF', 'HF',\n",
      "       'LF_HF', 'sum_f', 'rel_f', 'LF_norm', 'HF_norm', 'EDA_mean', 'EDA_std',\n",
      "       'EDA_min', 'EDA_max', 'EDA_range', 'EDA_slope', 'scl_mean', 'scl_std',\n",
      "       'scr_mean', 'scr_std', 'corr_scl_t', 'scr_count', 'scr_amp', 'scr_sum',\n",
      "       'scr_area', 'EMG_mean', 'EMG_std', 'EMG_median', 'EMG_p10', 'EMG_p90',\n",
      "       'EMG_range', 'EMG_sum', 'EMG_f_peak', 'EMG_psd_0_10Hz',\n",
      "       'EMG_psd_10_20Hz', 'EMG_psd_20_50Hz', 'EMG_psd_50_100Hz',\n",
      "       'EMG_psd_100_150Hz', 'EMG_psd_150_250Hz', 'EMG_psd_250_350Hz',\n",
      "       'EMG_peak_count', 'EMG_peak_amp_mean', 'EMG_peak_amp_std',\n",
      "       'EMG_peak_amp_sum', 'EMG_peak_amp_norm', 'Resp_mean', 'Resp_std',\n",
      "       'Resp_I_mean', 'Resp_I_std', 'Resp_E_mean', 'Resp_E_std',\n",
      "       'Resp_IE_ratio', 'Resp_range', 'Resp_insp_vol', 'Resp_rate',\n",
      "       'Resp_duration', 'Temp_mean', 'Temp_std', 'Temp_min', 'Temp_max',\n",
      "       'Temp_range', 'Temp_slope', '1', '2', '3', 'subject'],\n",
      "      dtype='object')\n",
      "Índices en counts: [1, 2, 3]\n",
      "Claves en int_to_label: dict_keys([1, 2, 3])\n",
      "Number of samples per class:\n",
      "baseline: 68659\n",
      "stress: 38904\n",
      "amusement: 21459\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "subject_ids = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17]\n",
    "\n",
    "combine_files(subject_ids)\n",
    "print('Processing complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holi\n"
     ]
    }
   ],
   "source": [
    "print('holi')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prepro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
